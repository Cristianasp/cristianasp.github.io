# Um apanhado de Machine Learning & Artificial Inteligence 

üìÖ Abril, 2023

Esse artigo √© base para um bate-papo que realizei com alguns professores de uma escola de neg√≥cios no Brasil em Abril-2023.

![](img/machine-learning-2.png)

  imagem produzida com intelig√™ncia artificial

---

# 1992: Turing e PROLOG

O ano era 1992. Era uma das primeiras turmas do curso "Engenharia de Computa√ß√£o" da UNICAMP. E eu teria uma aula da mat√©ria "Introdu√ß√£o a Intelig√™ncia Artificial", nova mat√©ria no novo curso. A professora apresentou durante 4 meses alguns assuntos sobre o tema. Algumas poucas coisas ficaram marcadas na minha cabe√ßa. Eram poucas mesmo, porque n√£o tinha muito assunto para as aulas. O que se podia falar de Intelig√™ncia Artificial na √©poca?

Lembro de dois assuntos que foram tratados ao longo da aulas: o teste de Turing e os programas em PROLOG.

O teste de Turing foi proposto em 1950 por Alan Turing. O objetivo do teste √© identificar se o entrevistador est√° conversando com uma pessoa ou uma m√°quina. A conversa √© atrav√©s da digita√ß√£o de textos. Sua premissa √© que se uma m√°quina conseguisse imitar o ser humano de maneira t√£o convincente que um ter√ßo de seus interlocutores acreditassem que estavam conversando com outro humano, esta m√°quina seria considerada "pensante" e ela passaria no teste.

PROLOG √© uma das primeiras linguagens associadas √† inteligencia artificial, foi criada em 1972. Resumidamente, PROLOG √© um linguagem que permite que sejam feitas associa√ß√µes l√≥gicas. No final do semestre, conseguimos fazer um programa que conseguia concluir algumas rela√ß√µes entre palavras a partir de algumas regras. 

E eu pensei: Como √© que um programa em PROLOG pode evoluir para algo similar a uma conversa inteligente? Como √© que o programa vai conseguir entender uma frase e a partir dela extrair o significado e responder, imitando um ser humano?

E pensei: acho que n√£o viverei pra ver isso... Pois √©, estava errada.

---

# E o que aconteceu nesses 30 anos?

## Mais m√°quina, mas mem√≥ria, mais dados

Dos anos 1990 at√© 2020, houve um crescimento exponencial na capacidade de armazenamento, processamento e tr√°fego de informa√ß√µes. Sem contar, obviamente, do crescimento exponencial na gera√ß√£o de informa√ß√£o.

Os n√∫meros s√£o at√© dif√≠ceis de imaginar.

![](img/OWID-cost.png)

![](img/OWID-tech.png)

A Lei de Moore √© baseada na constata√ß√£o que o n√∫mero de transistores em um microprocessador dobra a cada 2 anos. Em linguagem leiga, um transistor pode ser entendido como o √°tomo de um circuito (ou computador), no sentido que ele √© capaz de ligar ou desligar um sinal el√©trico (o tal 0 ou 1).

![](img/OWID-moore.png)

E medimos a capacidade de processamento de um computador em FLOPS: floating point operations per second, ou opera√ß√µes de ponto flutuante por segundo. √â uma opera√ß√£o aritim√©tica com um n√∫mero real, e √© considerado o melhor indicador para a capacidade de processamento de computadores.

![](img/OWID-supercomputer.png)

A diminui√ß√£o dos custos de armazenamento e processamento possibilitaram que grande parte da popula√ß√£o mundial tivesse acesso √† Internet. Com acesso, mais informa√ß√µes passaram a ser compartilhadas e armazenadas nos servi√ßos, gerando bases de dados com textos, imagens e v√≠deos que posteriormente seriam utilizados como dados para a Intelig√™ncia Artificial. 

Tr√°fego de informa√ß√µes na Internet mundial
![](img/internet-traffic.png)

A t√≠tulo de informa√ß√£o: h√° 1 zetta estrelas no universo...

Mais dados dispon√≠veis e a Lei de Moore foram os catalizadores da revolu√ß√£o de IA, que se iniciou em 1958 mas explodiu por volta de 2010.

O √∫ltimo ingrediente nesta receita de sucesso √© evolu√ß√£o da teoria relacionada a Machine Learning e ao aumento consider√°vel da produ√ß√£o de trabalhos acad√™micos.

O arXiv √© um servi√ßo de distribui√ß√£o gratuita e aberta que j√° recebeu, desde 2009, 2 milh√µes de artigos acad√™micos nas √°reas de f√≠sica, matem√°tica, ci√™ncia da computa√ß√£o, biologia quantitativa, finan√ßas quantitativas, estat√≠stica, engenharia el√©trica e ci√™ncia de sistemas e economia. Os materiais deste site n√£o s√£o revisados por pares pela arXiv.

Veja abaixo o crescimento de artigos relacionados √† ci√™ncia da computa√ß√£o (cs - em laranja), nos √∫ltimos 30 anos e nos √∫ltimos 2 anos:

![](img/arxiv-30-anos.png)

![](img/arxiv-2-anos.png)

E em ci√™ncia da computa√ß√£o, o crescimento exponencial de publica√ß√µes:

![](img/arxiv-submissoes-CS.png)

Vale observer a grande quantidade de artigos publicados recentemente nos temas abaixo destacados:

![](img/arxiv2.png)

cs.AI :Artificial inteligence https://arxiv.org/list/cs.AI/recent

cs.CL: Computation and Language https://arxiv.org/list/cs.CL/recent

cs.CV: Vision and Patter Recognition https://arxiv.org/list/cs.CV/recent

cs.HC: Human-Computer Interaction https://arxiv.org/list/cs.HC/recent

cs.LG: Machine Learning https://arxiv.org/list/cs.LG/recent



---

# Mas o que √© Machine Learning?

"Campo de estudo que d√° aos computadores a capacidade de aprender sem serem explicitamente programados" Arthur Samuel, 1959


![](img/machine-learning-1.png)

	Imagem produzida por intelig√™ncia artificial(openAI), com o texto da defini√ß√£o de machine learning acima.

At√© o final do s√©culo passado, era poss√≠vel programar uma m√°quina para executar tarefas e c√°lculos para resolver problemas. Mas existiam alguns tipos de problemas que eram dificeis de serem resolvidos atrav√©s da programa√ß√£o.

Houve um insight de que a √∫nica maneira de resolver esses problemas era fazer com que uma m√°quina aprendesse a resolv√™-lo sozinha. Inspirado em conceitos da estat√≠stica, da l√≥gica difusa e da teoria das probabilidades, surge o aprendizado de m√°quina.

Tom M. Mitchell, 1997, forneceu uma defini√ß√£o mais formal e amplamente citada:

"Um programa de computador aprende atrav√©s da experi√™ncia _E_ em rela√ß√£o a alguma classe de tarefas _T_ e tem um desempenho _P_ se o seu desempenho em tarefas T, medido por _P_, melhora com a experi√™ncia _E_." 

E - experi√™ncia : dados reais
T - tarefa: o resultado de um objetivo
P - desempelho: uma forma de medir se o objetivo foi alcan√ßado

Machine learning √© um campo da intelig√™ncia artificial cujo objetivo √© resolver problemas de forma p≈ïatica. 

Alguns exemplos de aprendizado de m√°quina:

- Estimar pre√ßo futuro de a√ß√µes
- Identificar fraudadores
- Identificar e extrair informa√ß√µes de imagens
- Carro aut√¥nomo
- Tradu√ß√£o de textos
- Identificar padr√µes em grande quantidade de dados:  dados m√©dicos, biologia - genoma
- Recomenda√ß√µes personalizadas: amazon, netflix

Portanto, para resolver os problemas cima, a abordagem da computa√ß√£o tradicional √© construir um programa com opera√ß√µes e c√°lculos, que precisam ser conhecidos e codificados. A abordagem de machine learning √© construir um programa que gere uma estimativa do resultado dos problemas acima, a partir de dados reais coletados. Para tal, haver√° uma etapa de aprendizado, que utilizar√° uma estrat√©gia iterativa, onde a cada intera√ß√£o, a estimativa ir√° melhorar.

---

# Como a m√°quina aprende?

![](img/DALL-E2023-04.png)

	DALL-e: A futuristic style picture of a man teaching a robot how to build a house.

### As m√°quinas podem aprender utilizando v√°rias estrat√©gias, sendo essas as principais:

- Supervised Learning (aprendizado supervisionado): ensinaremos a m√°quina a aprender, a partir de exemplos de dados reais e os resultados obtidos.

- Unsupervised Learning (aprendizado n√£o supervisionado): a m√°quina ir√° aprender por conta pr√≥pria e ir√° identificar padr√µes nos dados reais.

- Reinforcement Learning: iremos premi√°-la de acordo com o sucesso de seu aprendizado aut√¥nomo.

---

# Aplica√ß√µes para Supervised Learning (aprendizagem supervisionada)

Usamos para resolver esses tipos de problemas: 

**Problema de regress√£o**: Queremos prever resultados futuros a partir de dados conhecidos. Exemplos: Estimar o pre√ßo de novas casas a partir de dados de casas conhecidas (quantidade de quartos, bairro, √°rea, pre√ßo). Neste caso, temos dados cont√≠nuos.

**Problema de classifica√ß√£o**: Queremos saber a probabilidade de uma medi√ß√£o  pertencer a alguma classe conhecida. Exemplos: identificar se uma mensagem de email √© SPAM ou n√£o √© SPAM, identificar fraudes, identificar tumores em imagens. Neste caso, s√£o valores discretos.

Classifica√ß√£o bin√°ria (sim e n√£o)
- identificar spam
- identificar transa√ß√µes de fraudes
- identificar tumores em imagens

# Aplica√ß√µes para Unsupervised Learning (aprendizagem n√£o supervisionada)

Ao contr√°rio de Supervised Learning, n√£o h√° somente uma resposta correta!

Usamos quando queremos resolver esses tipos de problemas:

**Problema de Clusteriza√ß√£o**: A conversa √©: "M√°quina, aqui est√£o os dados, voc√™ consegue encontrar alguma "estrutura" nestes dados?" 

Exemplos: agrupar usu√°rios de redes sociais em perfis semelhantes, agrupar noticias em t√≥picos, agrupar humanos em grupos gen√©ticos, segmentar clientes para a√ß√µes de marketing, etc.

![](img/social-network.png)

	"A top view of a social network where each node is a person and each person has a different color"

**Problema do Cocktail Party**: Processamento de √°udio para remover sons de fundo, encontrando uma "estrutura" nos dados que desconhecemos.

![](img/singing.png)

  "A vintage image of one man e one woman singing in an antique microphone, each one holding its own microphone"

# Aplica√ß√µes para Reinforced Learning (Aprendizado por refor√ßo 

√â uma forma de aprendizado de m√°quina cujo objetivo √© obter o m√°ximo de recompensas, atrav√©s de tentativa e erro, em um ambiente.

Ou, em mais detalhe: 

"Reinforcement Learning (RL) √© a ci√™ncia da tomada de decis√£o. Trata-se de aprender o comportamento ideal em um ambiente para obter a m√°xima recompensa. Esse comportamento ideal √© aprendido atrav√©s de intera√ß√µes com o ambiente e observa√ß√µes de como ele responde, semelhante √†s crian√ßas que exploram o mundo ao seu redor e aprendem as a√ß√µes que as ajudam a alcan√ßar um objetivo.

Na aus√™ncia de um supervisor, o aluno deve descobrir de forma independente a sequ√™ncia de a√ß√µes que maximizam a recompensa. Esse processo de descoberta √© semelhante a uma pesquisa de tentativa e erro. A qualidade das a√ß√µes √© medida n√£o apenas pela recompensa imediata que eles retornam, mas tamb√©m pela recompensa atrasada que eles podem buscar. Como ele pode aprender as a√ß√µes que resultam em eventual sucesso em um ambiente invis√≠vel sem a ajuda de um supervisor, o aprendizado por refor√ßo √© um algoritmo muito poderoso"


![](img/Reinforcement_learning.png)

	imagem de https://www.synopsys.com/ai/what-is-reinforcement-learning.html

Exemplos de uso muito comuns: rob√≥tica e  jogos

![](img/rl-mario.png)

	imagem: https://www.youtube.com/watch?v=L4KBBAwF_bE

---

# Como os problemas de Machine Learning s√£o resolvidos? 

Para resolver um problema de machine learning, √© necess√°rio "treinar um modelo". Quando o modelo estiver treinado, ser√° poss√≠vel usar o modelo para fazer novas previs√µes.

E para o treinamento, precisaremos de:
- dados
- definir um modelo
- definir como iremos avaliar o desempenho do nosso modelo
- definir o algoritmo para treinamento

## Dados

Machine Learning precisa de muitos dados: muitas medi√ß√µes de exemplos reais, e com muitas vari√°veis. Vari√°veis podem ser medidas ou criadas a partir da combina√ß√£o de vari√°veis existentes. Vale a m√°xima de quanto mais, melhor.

N√∫meros atuais: 600 milh√µes de imagens, 450 bilh√µes de palavras

## Modelo 

Vamos come√ßar com um exemplo simples, queremos estimar o pre√ßo de uma casa, usando o **modelo de regress√£o linear de uma vari√°vel**. Nossa equa√ß√£o √© `a+bx=y`. Partimos de amostras de dados, que s√£o medi√ß√µes de `x` e `y`. Nosso processo √© tentar descobrir `a` e `b` para podermos estimar novos valores de `x` e `y`. 

Agora um problema um pouco mais complexo, queremos classificar imagens de tumores 2 valores (sim ou n√£o para c√¢ncer), poder√≠amos tamb√©m usar a regress√£o linear, mas ela √© muito "simples" e  precisamos de uma maior sensibilidade para pequenas mudan√ßas nas vari√°veis.

Usaremos a **regress√£o log√≠stica**, que calcula a `probabilidade` do resultado ser `1`, dada uma vari√°vel `x`, escolhendo valores `a` e `b`. Sendo assim, o resultado do modelo s√£o probabilidades, e da√≠ √© poss√≠vel escolher o ponto de corte (decision boundary) para considerar 0 e 1 (normalmente 0.5).

Existem muitos outros modelos que podem ser usados em machine learning.

## Desempenho do modelo

Durante o treinamento, como saberemos se  `a` e `b` escolhido s√£o bons ? Queremos minimizar a soma dos erros de cada resultado `y` calculado de todos os exemplos de dados, variando `a` e `b`. 

Para regress√£o linear, usamos uma fun√ß√£o matematicamente mais eficiente do que a soma simples dos erros, que √© a fun√ß√£o da soma dos erros quadr√°ticos (squared error function). Existe uma caracter√≠stica muito importante no formato da fun√ß√£o erro: esta fun√ß√£o √© escolhida de forma a sempre ter um valor m√≠nimo.

Para regress√£o log√≠stica, precisamos de outra fun√ß√£o para o erro. Se usarmos a soma do quadrado dos erros, teremos uma fun√ß√£o n√£o convexa, com v√°rios m√≠nimos locais. Precisamos de uma fun√ß√£o convexa para a fun√ß√£o custo.

![](img/logreg-pred.png)

Usamos uma fun√ß√£o que tem o seguinte formato:
`-y log (f(x)) - (1 - y) log (1 - f(x))`
Essa fun√ß√£o √© convexa, acredite.

## Algoritmo para treinamento

O que queremos fazer ? N√≥s queremos encontrar valores dos coeficientes da fun√ß√£o cujo resultado calculado seja o mais pr√≥ximo do resultado real, ou seja, queremos minimizar o erro.

**Assim chegamos ao objetivo do algoritmo de machine learning, que √© resolver um problema de minimiza√ß√£o  / otimiza√ß√£o.** 

E por isso precisamos de uma fun√ß√£o erro que tenha um valor m√≠nimo. Abaixo um exemplo da vis√£o tridimensional de uma fun√ß√£o com duas vari√°veis.

![](img/01-10.png)


Mas como encontrar os valores dos coeficientes da fun√ß√£o que minimizem a fun√ß√£o erro? O algoritmo amplamente utilizado em Machine Learning chama-se **Gradient Descent**. 

Funciona assim:
- escolha um valor para `a` e `b` e calcule a fun√ß√£o erro.
- altere `a` e `b` e calcule a fun√ß√£o e veja se a fun√ß√£o diminuiu.
- repita os passos acima at√© parar de diminuir.

Pegadinha:
- para escolher um novo valor para `a` e `b`, a dica √© fazer a conta utilizando o algoritmo gradient descent . Essa etapa tem duas escolhas importantes que devem ser feitas: o `tamanho do passo` (learning rate) e a `dire√ß√£o do passo` (derivada da fun√ß√£o erro com `a` e `b` neste ponto).

Uma observa√ß√£o: adicionar mais vari√°veis para resolver problemas de regress√£o linear apenas aumenta a dimens√£o e neste caso passamos a usar matrizes e vetores.

Outra observa√ß√£o: Os algoritmos possuem diversos par√¢metros que precisam ser definidos, mas vamos manter as coisas simples por aqui.

---
# Resume por favor

Concluindo, estamos trabalhando com c√°lculos matem√°ticos para acharmos valores de vari√°veis que representem uma fun√ß√£o desconhecida, que quando √© aplicada, ter√° resultados mais semelhantes poss√≠veis aos dados usados para  "treinar" nosso modelo.

O c√°lculo √© quase por tentativa e erro. Partimos de uma situa√ß√£o inicial aleat√≥ria (ou quase isso) e seguimos passos para otimizar a fun√ß√£o erro (errar menos). Contamos com a matem√°tica para nos ajudar e dar os passos do tamanho certo, na dire√ß√£o certa.

![](img/gradient-descent-2.png)

	 "A top view of several men walking in different directions in several roads that all converges to a unique red point in the middle of the view"

![](img/gradient-descent-1.png)

	"A top view of several men walking in different directions in several roads that all converges to a unique red point in the middle of the view"

---

# Overfitting e Underfitting

Fala-se pouco desse assunto, mas o tema √© extremamente importante. 

Underfitting ou high bias (vi√©s alto) ocorre quando a fun√ß√£o de estimativa mapeia mal a tend√™ncia dos dados. Geralmente √© causada por uma fun√ß√£o que √© muito simples ou usa poucas vari√°veis.

Overfitting ou high variance (vari√¢ncia alta) ocorre quando a fun√ß√£o de estimativa se ajusta demasiadamente aos dados dispon√≠veis, mas n√£o generaliza bem para prever novos dados. Geralmente √© causada por uma fun√ß√£o complicada que cria muitas curvas e √¢ngulos desnecess√°rios, que s√£o relacionados a dados at√≠picos.

Nossos dados de treinamento:

![](img/fastai_overff_73_0.png)

Treinamento com uma fun√ß√£o muito simples (underfitting):

![](img/fastai_overff_77_0.png)

Treinamento com uma fun√ß√£o muito complexa (overfitting):

![](img/fastai_overff_79_0.png)

Um bom treinamento (fun√ß√£o ideal e fun√ß√£o encontrada):

![](img/fastai_overff_81_0.png)

	imagens extraidas de: https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners

Portanto os dados de treinamento s√£o extremamente importantes em machine learning. Dados enviesados levam a modelos enviesados. Dados com pouca varia√ß√£o levam a um modelo que n√£o representa a realidade. E modelos treinados erroneamente s√£o bons para os dados de treinamento e p√©ssimos para novas previs√µes.

√â pra isso que existem os engenheiros de Machine Learning, que cuidam disso e de muitos outros detalhes...

E nunca podemos nos esquecer que modelos tratam **sempre** com probabilidades e s√£o estimativas. Nunca acertar√£o tudo. Errar√£o. 

---

# Como surgiram as redes neurais?

Na d√©cada de 80 foram produzidas diversas pesquisas no c√©rebro de animais e supreendentemente constatou-se que o mesmo tecido do c√©rebro poderia ser conectado a qualquer sensor do c√©rebro e aprender novas fun√ß√µes relacionadas ao novo sentido. A hip√≥tese era que se um mesmo tecido do c√©rebro conseguia processar som ou tato ou vis√£o, deveria haver um algoritmo intr√≠nsico e "gen√©rico" no neur√¥nio que permitia que ele processasse som ou tato ou vis√£o. E portanto, ao inv√©s de termos c√©lulas diferenciadas com fun√ß√µes especializadas, o c√©rebro era composto por unidades semelhantes, com um mesmo √∫nico algoritmo de aprendizagem. 

A id√©ia era identificar este algoritmo de aprendizado do c√©rebro e reproduzi-lo digitalmente. Um algoritmo aproximado ao processo animal parecia promissor e representava um progresso real em dire√ß√£o √† intelig√™ncia artificial e o sonho de construir m√°quinas inteligentes.

Essa id√©ia foi muito discutida ao longo das d√©cadas de 1980 e 1990, mas pelas restri√ß√µes tecnol√≥gicas da √©poca, conforme j√° apresentado, sua popularidade diminuiu no final dos anos 90. Mas a partir de 2012 as redes neurais resssurgiram e conseguiram resolver diversos problemas. 

As redes neurais foram um sucesso pois existem situa√ß√µes nas quais a modelagem tradicional com regress√£o linear, log√≠stica ou outros modelos n√£o s√£o suficientes para resolver problemas **mais complexos** ou com **mais vari√°veis**, onde √© computacionalmente imposs√≠vel processar todas as poss√≠veis fun√ß√µes de grau-n para todo o conjunto de vari√°veis. As redes neurais surgiram como inova√ß√£o para resolver esses tipos de problemas.

Elas s√£o at√© o presente momento, uma t√©cnica de √∫ltima gera√ß√£o para muitas aplica√ß√µes.

![](img/img-neurons.png)

	prompt: "several conected neurons creating a neural network"

---

# E o que √© um neur√¥nio digital?

O neur√¥nio digital mimifica o neur√¥nio biol√≥gico em seus componentes e fun√ß√µes. 

O neur√¥nio biol√≥gico possui diversas conex√µes de entrada chamadas dentrites, um n√∫cleo e uma conex√£o de sa√≠da chamada axioma, que se conecta a outros dentrites de outros neur√¥nios.

O neur√¥nio digital possui diversas vari√°veis de entrada, uma fun√ß√£o de "ativa√ß√£o" e uma sa√≠da, que se conectar√° √† entrada de outro neur√¥nio digital.

![](img/comparison-nn--human.png)

	fonte da imagem: https://www.researchgate.net/publication/339446790_Using_a_Data_Driven_Approach_to_Predict_Waves_Generated_by_Gravity_Driven_Mass_Flows


Fazendo a analogia, os neur√¥nios possuem vari√°veis de entradas (dendrites), uma fun√ß√£o matem√°tica que "processa" as entradas, calculando o produto entre os pesos, tamb√©m chamados de par√¢metros, atribu√≠dos arbitrariamente a cada vari√°vel e em seguida aplicando uma fun√ß√£o n√£o linear no seu "n√∫cleo", e uma sa√≠da desse processamento (axioma).

A fun√ß√£o de ativa√ß√£o mais comum √©, ou era, a log√≠stica, e sendo assim, as redes neurais ter√£o como sa√≠das valores cont√≠nuos entre zero e um.

---

# E como √© uma rede neural ?

Para criar uma rede neural, v√°rias camadas de neur√¥nios s√£o adicionadas, sendo que na maioria das vezes a entrada de uma camada √© a sa√≠da da camada anterior e assim por diante, at√© a √∫ltima camada, que pode ter um ou mais neur√¥nios, dependendo do problema que √© modelado.

![](img/nn-topology.webp)

	 imagem de https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464

---

# E como um neur√¥nio digital aprende ?

Quando falamos de regress√£o e classifica√ß√£o, o processo de aprendizado comprende definir uma fun√ß√£o erro e executar um algoritmo que a cada passo busca minimizar a fun√ß√£o erro, atrav√©s de estrat√©gias matem√°ticas como o gradient descent. Isso tudo √© feito com dados que possuem tanto os valores das vari√°veis como o resultado esperado, ou seja, estamos falando de "aprendizado supervisionado".

Nas redes neurais, o processo √© semelhante, mas com algumas especifidades. Existe uma fun√ß√£o erro que deve ser minimizada (um pouco mais complexa matematicamente) e tambem utiliza-se o gradient descent. 

A fun√ß√£o erro parece assustadora matematicamente, mas no portugu√™s fica simples: √© a diferen√ßa entre o valor calculado (previsto) e o valor real - valor do resultado que est√° na base de dados utilizada para o treinamento. 

![](img/04-20-b.png)

E no algoritmo de otimiza√ß√£o s√£o executados dois passos: 
- Forward propagation: um passo no sentido das entradas para a sa√≠da, com o objetivo de calcular a fun√ß√£o erro.
- Backward propagation: um passo no sentido das sa√≠das para as entradas, com o objetivo de ajustar os valores dos par√¢metros (pesos) de cada vari√°vel para minimizar ainda mais o erro, atrav√©s do c√°lculo de derivadas parciais da fun√ß√£o erro.

![](img/forward-process-and-error-backpropagation.png)

	imagem de https://www.researchgate.net/figure/The-illustration-of-the-forward-process-and-error-backpropagation-in-the-SSTDP-method_fig4_355905487

---

# Alguns marcos das redes neurais

## Lenet5 - Leitura de c√≥digos postais dos correios - 1998

![](img/lenet5.gif)

@ AT&T - Lenet5 - 1998
Yann LeCun, Leeon Bottou, Yoshua Bengio, and Patrick Haffner

## AlexNet - reconhecimento de imagens - 2012

![](img/imagenet.png)

Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton
650,000 neurons, and 60 million parameters, 1000 different classes
competi√ß√£o Imagenet - 1.2 million images in the ImageNet LSVRC-2010 
uso das GPUs

## Revolu√ß√£o do Deep learning - 2013+

Big techs: Google, Facebook, Apple, etc
Cria√ß√£o dos CHIPS especializados: Tensor(Google), Tesla (NVIDIA), Intel, Amazon, Microsoft, Tesla.

## Concurso Imagenet

![](img/imagenet-error.png)

	fonte: https://arstechnica.com/science/2019/12/how-neural-networks-work-and-why-theyve-become-a-big-business/

---

# Mas como uma rede neural consegue entender uma imagem?

A revolu√ß√£o das redes neurais veio com a solu√ß√£o de problemas relacionados a imagens, tamb√©m conhecidos como problemas de vis√£o computacional.

Uma estrat√©gia extremamente importante para a vis√£o computacional √© a convolu√ß√£o (convolutions) aplicada √†s redes neurais, nas chamadas CNN - convolutional neural networks.

A convolu√ß√£o √© uma opera√ß√£o matem√°tica aplicada em redes neurais para extrair caracter√≠sticas dos dados de entrada. Envolve aplicar um filtro deslizante sobre a imagem de entrada e criar uma nova representa√ß√£o de sa√≠da com base nos pesos do filtro.

Uma convolu√ß√£o captura a rela√ß√£o entre um pixel e seus pixels vizinhos em uma imagem, aplicando um filtro √† imagem original. Esse processo ajuda a identificar a presen√ßa de caracter√≠sticas como bordas ou outros padr√µes na imagem de entrada, o que pode ser √∫til em tarefas como reconhecimento de objetos (classifica√ß√£o) em vis√£o computacional. 

![](img/convolution-animated.gif)

	imagem: https://indiantechwarrior.com/convolution-layers-in-convolutional-neural-network/

O mapa de uma convolu√ß√£o resume as caracter√≠sticas extra√≠das e pode ser processado pelas camadas subsequentes da rede neural para extrair novas caracter√≠sticas mais complexas. Essa extra√ß√£o hier√°rquica das caracter√≠sticas melhora a capacidade da rede de classificar ou detectar com precis√£o objetos em imagens.

![](img/convolution-schema.webp)


Nas imagens abaixo √© poss√≠vel visualizar o que cada camada da rede neural est√° identificando como um padr√£o. A cada camada, os padr√µes se tornam mais complexos, pois podem se beneficiar do aprendizado das camandas anteriores.

![](img/fastai-convolutions-01.png)

![](img/fastai-convolutions-02.png)

![](img/fastai-convolutions-03.png)

![](img/fastai-convolutions-04.png)

	imagens de https://github.com/fastai/fastbook/blob/master/01_intro.ipynb

---

# Processamento de linguagem natural, ou natural language processing - NLP

√â o campo de estudo da computa√ß√£o cujo objetivo √© pesquisar sobre formas de intera√ß√£o entre os computadores e humanos, utilizando a linguagem.
(human-computer interaction).

Os algoritmos mais antigos eram baseados em programas desenvolvidos com conceitos l√©xicos, ou seja, atrav√©s de regras e estrat√©gias para tratar as palavras pertencentes a um dicion√°rio. 

Exemplo m√©todo l√©xico: mapear palavras como positivas e negativas e atribuir um valor, processar um texto e gerar um score final e de acordo com este valor, definir se √© uma frase com sentimento positivo ou negativo.

J√° os algoritmos modernos de NLP s√£o baseados em machine learning. Isso porque as id√©ias, aplica√ß√µes e inova√ß√µes em machine learning  foram tamb√©m aplicadas para resolver problemas relacionados √† linguagem.

√â certo dizer que esse campo de estudo √© muito recente e evoluiu muito a partir de meados de 2010.

# O que pode ser feito com NLP:

- Responder quest√µes (Question answering)
- Reconhecimento da fala (Speech recognition)
- Texto para voz e voz para texto (Text-to-speech and Speech-to-text)
- Classifica√ß√£o de textos (Topic modeling)
- Classifica√ß√£o de sentimentos (Sentiment classification)
- Sugerir a pr√≥xima palavra no teclado do seu telefone (Language modeling)
- Tradu√ß√£o
- Marcadores de classe gramatical (Part-of-speech tagging): identificar substantivos, verbos, adjetivos, etc
- Identificar entidades nomeadas (Named entity recognition NER): personalidades, organiza√ß√µes, locais, c√≥digos da medicina, data-hora, moedas, etc

---

# A m√°gica da matem√°tica de word-embeddings

Palavras n√£o s√£o coisas que os computadores naturalmente entendem. Ao codificar palavras em uma forma num√©rica, podemos aplicar regras matem√°ticas e fazer opera√ß√µes com elas. Essa transforma√ß√£o permite fazermos coisas incr√≠veis com os textos utilizando machine learning.

Em 2013, pesquisadores do Google publicaram um artigo e um software chamado `word2vec` que foi um marco para o NLP. Em seguida veio o `fasttext` do Facebook e o `glove` de Stanford. Esses algoritmos s√£o conhecidos como 
**word embeddings est√°ticos ou cl√°ssicos**, pois cada palavra ter√° sempre a mesma representa√ß√£o, independente do contexto onde ela ocorrer.

Word-embeddings s√£o uma maneira de representar palavras como vetores num√©ricos em um espa√ßo de muitas dimens√µes. Para gerar essa representa√ß√£o vetorial, senten√ßas com v√°rias palavras s√£o treinadas em uma rede neural, com o objetivo de prever a distribui√ß√£o da probabilidade da ocorr√™ncia das palavras vizinhas para cada palavra do vocabul√°rio (ou o dicion√°rio). E o vetor para cada palavra √© extra√≠do de dentro da rede neural.

Como exemplo:  ‚Äúking‚Äù (vetor GloVe treinado na wikipedia):
`[ 0.50451 , 0.68607 , -0.59517 , -0.022801, 0.60046 , -0.13498 , -0.08813 , 0.47377 , -0.61798 , -0.31012 , -0.076666, 1.493 , -0.034189, -0.98173 , 0.68229 , 0.81722 , -0.51874 , -0.31503 , -0.55809 , 0.66421 , 0.1961 , -0.13495 , -0.11476 , -0.30344 , 0.41177 , -2.223 , -1.0756 , -1.0783 , -0.34354 , 0.33505 , 1.9927 , -0.04234 , -0.64319 , 0.71125 , 0.49159 , 0.16754 , 0.34344 , -0.25663 , -0.8523 , 0.1661 , 0.40102 , 1.1685 , -1.0137 , -0.21585 , -0.15155 , 0.78321 , -0.91241 , -1.6106 , -0.64426 , -0.51042 ]`

Uma das propriedades interessantes das word-embeddings √© que palavras com significados semelhantes tendem a ser agrupadas no mesmo espa√ßo dimensional. 

![](img/king-man-woman-embedding.png)

	 imagem: https://jalammar.github.io/illustrated-word2vec/

Quando constru√≠mos este "espa√ßo" com os vetores mapeados, conseguimos capturar algum tipo de relacionamento nesse espa√ßo, seja significado, morfologia, contexto ou algum outro tipo de relacionamento.

![](img/word-embeddings-2.webp)


Em seguida surgiram novas t√©cnicas para agrupamento das palavras, conhecidos como **word embeddings din√¢micos ou contextualizados**, que levam em considera√ß√£o o contexto da palavra dentro de uma frase. Como exemplo: `ELMO` (2018) e `BERT` (2018). Neste caso, palavras em contextos diferentes podem ter representa√ß√µes diferentes.

---

# Como ocorre o processamento de linguagem natural ?

Normalmente ele tem algumas etapas, que podem acontecer ou n√£o, dependendo da estrat√©gia adotada:

Etapa de prepara√ß√£o dos dados, ou **pr√©-processamento**:

- Tokenization: definir uma "unidade" de processamento de uma frase.

- Remo√ß√£o de stopwords: artigos, conjun√ß√µes, adv√©rbios, etc

- Stemming: manter somente a raiz de cada palavra
walking - walk

- Lemmatization: mapear as palavras para seu lema
walking - walk
better - good

- Word-Embeddings

- Dentre outros...

**Treinamento**: utiliza√ß√£o de um algoritmo escolhido para processar os dados preparados, com v√°rios par√¢metros de configura√ß√£o definidos.

**Infer√™ncia**: √© o momento em que executamos de fato o algoritmo j√° treinado, utilizando novos dados que ser√£o processados.

---

# Principais abordagens para resolver problemas de NLP

Existem tr√™s principais abordagens para a solu√ß√£o de problemas de NLP:

Vamos ver as diferentes abordagens para resolver o problema de  preenchimento sem√¢ntico de espa√ßos - semantic slot filling :

![](img/semantic-slot-filling.webp)

	 imagem extra√≠da de https://medium.com/koderunners/semantic-slot-filling-part-1-7982d786928e

1. Algoritmos baseados em regras:

O texto √© analisado e s√£o identificadas as partes do texto que correspondem √†s regras previamente definidas que representam a estrutura do texto.

![](img/ssf1.png)


2. Algoritmos baseados em Machine Learning "tradicional"

Para o mesmo problema acima, um exemplo de algoritmo de machine learning √© o CRF (Conditional Random Field). Neste caso, √© necess√°rio ter muitos dados de treinamento anotados (preparados). Em seguida s√£o criadas diversas vari√°veis relacionadas ao resultado do problema a ser resolvido. Ent√£o define-se um modelo matem√°tico que produzir√° a probabilidade de um texto a partir das palavras. Com o modelo treinado, durante a infer√™ncia (previs√£o), o resultado escolhido √© o de maior probabilidade.

![](img/ssf2.png)

H√° muitos outros algoritmos de machine learning para resolver problemas de NLP, tais como decision trees (√°rvores de decis√£o), matrix decomposition (decomposi√ß√£o de matrizes), hiden markov, etc

3.  Algoritmos beseados em Deep Learning (Redes Neurais complexas)

Neste caso, tamb√©m √© necess√°ria uma grande quantidade de dados de treinamento. Mas n√£o √© necess√°rio criar novas vari√°veis, basta carregar esses dados na rede neural e trein√°-la. O resultado ter√° uma s√©rie de vari√°veis de sa√≠das com suas probabilidades.

![](img/ssf3.png)

---

# Mais alguns exemplos de algoritmos que podem ser utilizados:

Texto criado pelo chatGPT em ingl√™s e traduzido por ele mesmo ;-)

## Modelos n√£o baseados em redes neurais:

Bag-of-Words: Uma maneira simples e eficaz de representar dados de texto, onde cada documento ou senten√ßa √© representado como um saco de palavras, onde a frequ√™ncia de cada palavra √© usada como caracter√≠stica. Isso pode ser usado para tarefas como an√°lise de sentimentos, classifica√ß√£o de documentos e modelagem de t√≥picos.

N-gramas: Usando sequ√™ncias cont√≠guas de N palavras como caracter√≠sticas para capturar informa√ß√µes contextuais em dados de texto. Isso pode ser usado para tarefas como modelagem de linguagem, classifica√ß√£o de texto e tradu√ß√£o autom√°tica.

TF-IDF: Um esquema de pondera√ß√£o que atribui um peso a cada palavra em um documento com base em com que frequ√™ncia ela aparece nesse documento e em como ela √© rara em todos os documentos. Isso pode ser usado para melhorar a efic√°cia da abordagem do saco de palavras (B-O-W)

M√°quinas de Vetores de Suporte (SVMs): Um algoritmo popular de aprendizado de m√°quina que pode ser usado para classifica√ß√£o de texto e outras tarefas de PNL. Eles funcionam encontrando um hiperplano que separa os dados em diferentes classes.

Naive Bayes: Um modelo probabil√≠stico simples e eficaz que pode ser usado para classifica√ß√£o de texto e outras tarefas de PNL. Ele funciona calculando a probabilidade de cada classe a partir dos dados de entrada e escolhendo a classe mais prov√°vel.

√Årvores de Decis√£o: Um algoritmo popular de aprendizado de m√°quina que pode ser usado para classifica√ß√£o de texto e outras tarefas de PNL. Eles funcionam particionando recursivamente os dados em subconjuntos com base nos valores das caracter√≠sticas de entrada e escolhendo a caracter√≠stica que resulta na melhor divis√£o em cada n√≥.

Modelos Ocultos de Markov (HMMs): Um tipo de modelo probabil√≠stico usado para modelar sequ√™ncias de dados em que o estado subjacente n√£o √© diretamente observ√°vel, mas √© assumido como gerador dos dados observados. HMMs podem ser usados para uma variedade de tarefas de PNL, como marca√ß√£o de partes do discurso, reconhecimento de entidades nomeadas e reconhecimento de fala.

## Modelos baseados em redes neurais:

Redes Neurais Recorrentes (RNNs): Um tipo de rede neural que √© bem adequado para processar dados sequenciais, como texto. Eles s√£o comumente usados ‚Äã‚Äãpara tarefas como modelagem de linguagem, tradu√ß√£o autom√°tica e an√°lise de sentimento.

Redes Long Short-Term Memory (LSTM): Um tipo de RNN projetado para lidar com o problema do gradiente que desaparece, que pode ocorrer ao treinar RNNs tradicionais em sequ√™ncias longas de dados. LSTMs s√£o comumente usados ‚Äã‚Äãpara modelagem de linguagem, tradu√ß√£o autom√°tica e reconhecimento de fala.

Redes Neurais Convolucionais (CNNs): Um tipo de rede neural que √© tipicamente usada para reconhecimento de imagem, mas pode ser adaptada para classifica√ß√£o de texto e outras tarefas de PLN.

Modelos de Transformadores: Um tipo de rede neural baseado em um mecanismo de autoaten√ß√£o, que permite que o modelo selecione seletivamente diferentes partes dos dados de entrada. Os modelos de transformadores s√£o comumente usados ‚Äã‚Äãpara tarefas como modelagem de linguagem, tradu√ß√£o autom√°tica e resposta a perguntas.

Word Embeddings: Uma t√©cnica para representar palavras como vetores em um espa√ßo de alta dimens√£o. Eles s√£o comumente usados ‚Äã‚Äãcomo recursos de entrada para redes neurais e outros modelos de aprendizado de m√°quina.

Mecanismos de Aten√ß√£o: Uma t√©cnica para permitir que redes neurais se concentrem seletivamente em diferentes partes dos dados de entrada, dependendo da tarefa em quest√£o. Eles s√£o comumente usados ‚Äã‚Äãna tradu√ß√£o autom√°tica neural e outras tarefas de sequ√™ncia a sequ√™ncia.

Autoencoders: Um tipo de rede neural usado para aprendizado n√£o supervisionado, onde o objetivo √© aprender uma representa√ß√£o comprimida dos dados de entrada. Autoencoders podem ser usados ‚Äã‚Äãpara tarefas como gera√ß√£o de texto e resumo de texto.

Redes Advers√°rias Generativas (GANs): Um tipo de rede neural que consiste em duas partes: um gerador que gera novas amostras de dados e um discriminador que tenta distinguir entre as amostras geradas e as amostras reais. GANs podem ser usados ‚Äã‚Äãpara tarefas como gera√ß√£o de texto e transfer√™ncia de estilo.

---

# Attention e transformers

At√© 2017, o algoritmo mais utilizado em NLP para problemas relacionados a tradu√ß√£o e modelos de linguagem (LM = language models) era a RNN (recurrent neural networks).

As RNNs processam palavra por palavra em um texto, seu treinamento √© lento e possuiam uma limita√ß√£o na quantidade de palavras que podiam ser processadas (cerca de mil).  Sua vantagem √© poder identificar as rela√ß√µes posicionais, ou o contexto, entre as palavras em uma frase. As RNN eram muito boas para traduzir texto, mas n√£o eram t√£o boas para gerar novos textos. Havia tambem algumas solu√ß√µes utilizando CNN (convolutions neural networks).

Em Junho de 2017 foi publicado um artigo considerado um marco no processamento de NLP, chamado "Attention is all you need", de autoria de pesquisadores do Google Brain, Google Research e da Universidade de Toronto. Neste artigo, os autores propuseram uma nova arquitetura de redes neurais, chamada **Transformer**, que n√£o estava baseada em recorr√™ncia ou convolu√ß√µes, mas sim em aten√ß√£o.

Enquanto durante o treinamento de uma rede neural a convolu√ß√£o identifica as rela√ß√µes posicionais entre as palavras, a aten√ß√£o olha para todas as palavras procurando identificar conex√µes. O segredo est√° em ser seletivo e identificar quais palavras s√£o mais importantes em um contexto espec√≠fico. 

O conceito de aten√ß√£o √© crucial na arquitetura dos transformers, permitindo ao modelo focar em diferentes partes do texto de entrada, de acordo com a relev√¢ncia destas partes do texto relacionadas ao problema sendo resolvido.

![](img/transformer_self-attention_visualization.png)

	imagem de http://jalammar.github.io/illustrated-transformer/


A arquitetura Transformer √© um exemplo espec√≠fico dos modelos baseados em encoder-decoder (codificador-decodificador) que se tornaram populares pouco mais de 2 a 3 anos antes. At√© aquele momento, no entanto, a aten√ß√£o era apenas um dos mecanismos utilizados por esses modelos, que se baseavam principalmente em varia√ß√µes LSTM (Long Short Term Memory) e outras RNN (Recurrent Neural Networks). O principal insight do artigo de Transformers foi que, como o t√≠tulo indica, a aten√ß√£o poderia ser usada como o √∫nico mecanismo para derivar depend√™ncias entre entrada e sa√≠da.

Al√©m disso, os Transformers podem processar a sequencia de palavras de entrada sem a necessidade de realizar computa√ß√£o em cada item em sequ√™ncia, e isso permitiu que o processamento da entrada pudesse ser **paralelizado**. O impacto dessa abordagem √© que o tempo de treinamento diminuiu na ordem de 1000 vezes (10e18 versus 10e21 FLOPS). 

Por outro lado, h√° uma limita√ß√£o que √© o aumento da complexidade proporcionalmente ao texto de entrada, sendo que o limite em 2021 estava em 384 tokens.

# Exemplos de transformers ?

Inicialmente os Transformers foram treinados para tradu√ß√£o (Ingl√™s -Alem√£o).

Uma das principais vantagens dos Transformers √© a sua capacidade de adaptar a outras tarefas que n√£o foram objeto do treinamento, tamb√©m conhecidas como Transfer√™ncia de aprendizado (transfer learning). Os modelos podem se adaptar de forma extremamente f√°cil e r√°pida atrav√©s de um ajuste fino (fine tunning) com um conjunto de dados bem menor.

Al√©m de serem usados para tarefas relacionadas a texto, os Transformers foram treinados como **modelos multimodais** (multimodel), que processavam imagens, √°udio, m√∫sicas e textos e eram capazes de efetuar tarefas diversas, tais como tradu√ß√£o, descri√ß√£o de uma imagem, categorizar textos, etc.

Vale mencionar a cria√ß√£o de uma startup que foi criada em torno da id√©ia de comercializar seu c√≥digo aberto de modelos de Transformers, chamada HuggingFace, que j√° recebeu 60 milh√µes de d√≥lares at√© 2023. https://huggingface.co/

A arquitetura de transformers passou a ser largamente utilizada, e surgiram dezenas de modelos como BERT, GPT, PaLM, DALL-E, Stabe Difusion, etc.

![](img/transformers-timeline.png)

	fonte: https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/

Esses modelos s√£o inicialmente treinados para modelos de linguagem (LLM = large language models), com o objetivo de prever o pr√≥ximo texto em uma frase, e por esse motivo, s√£o conhecidos como **generativos**.

Ap√≥s o treinamento, podem ocorrer etapas etapas e estrat√©gias posteriores para ajuste fino da performance do modelo, de acordo com o objetivo.

Alguns trabalhos mais recentes est√£o focados em remover algumas barreiras de treinamento dos Transformers para deix√°-los mais dispon√≠veis. Mas hoje, somente grandes corpora√ß√µes s√£o capazes de treinar esses grandes modelos de linguagem.

---

# Chegamos no chatGPT ?

Sim! Chegamos no chatGPT.

**ChatGPT √© um chatbot que usa o modelo de linguagem do GPT** para interagir com humanos de forma conversacional. Ele foi  otimizado para di√°logo por treinadores humanos.

O GPT √© um Generative Pre-trained Transformer (GPT).

![](img/chatgpt.png)


O processo de treinamento do GPT inclui uma etapa de treinamento como um modelo de linguagem.

![](img/gpt3.png)

E uma segunda etapa chamada Reinforcement Learning from Human Feedback (RLHF), no qual foram geradas respostas diferentes para um di√°logo, e humanos classificaram essas respostas. Essas notas, tambem conhecidas como feedback, foram usadas para treinar uma fun√ß√£o de recompensa,  no contexto de aprendizado por refor√ßo (Reinforced Learning). 

Essa segunda etapa e outras estrat√©gias que foram aplicadas ao modelo s√£o conhecidas como "alinhamento e seguran√ßa".

![](img/gpt-perf.png)
	fonte: https://arxiv.org/abs/2303.08774

Perguntei para o chatGPT como √© seu processo de treinamento e infer√™ncia e ele respondeu. Tem bastante chance da resposta estar correta: 

[chat-GPT by chat-GPT](chat-GPT-by-himself)

---

# E o que nos espera?

Em 30/11/2022, a OpenAI lan√ßou o chatGPT. 

Em 01/02/2023, o chatGPT Plus. 

Em 14/03/2023, o GPT-4.

Em 14/03/2023, o Bing Chat da Microsoft passou a usar o GPT-4.

EM 24/02/2023, a Meta lan√ßou o LLaMA (Large Language Model Meta AI)

Em 14/03/2023, o Google liberou acesso ao PaLM, criado em Abril de 2022

Em 31/03/2023, alguns especialistas divulgaram um manifesto pedindo que as pesquisas al√©m do GPT-4 fossem pausadas por 6 meses.
https://futureoflife.org/open-letter/pause-giant-ai-experiments/

Nestes tempos, s√£o novidades di√°rias sobre os LLMs (Large Language Models). Manter-se atualizado j√° √© um desafio para um humano.

Eu destaco alguns temas que tem sido bastante abordados:

## Seguran√ßa e alinhamento

Do pr√≥prio artigo sobre o GPT4 :
		
"Despite its capabilities, [...] it is not fully reliable (e.g. can suffer from ‚Äúhallucinations‚Äù), has a limited context window, and does not learn from experience. Care should be taken when using the outputs of GPT-4, particularly in contexts where reliability is important. GPT-4‚Äôs capabilities and limitations create significant and novel safety challenges, and we believe careful study of these challenges is an important area of research given the potential societal impact."

https://arxiv.org/abs/2303.08774

Um dos signat√°rios to tal manifesto (Gary Marcus):

The real danger is "MAI risk - Mediocre AI that is unreliable (a la Bing and GPT-4) but widely deployed - both in terms of the sheer number of people using it, and in terms of the¬†access¬†that the software has to the world"

https://garymarcus.substack.com/p/ai-risk-agi-risk

![](img/tweet-gm.png)


Europol:

Phishing & online fraud can be created faster, much more authentically, & at significantly increased scale. [...] LLMs can be abused ..to mislead potential victims into placing their trust in the hands of criminal actors. [...] May facilitate terrorist activities.

https://www.europol.europa.eu/media-press/newsroom/news/criminal-use-of-chatgpt-cautionary-tale-about-large-language-models

Sobre Alinhamento (Jascha Sohl-Dickstein - Google Brain):

"The more intelligent an agent is, the less coherent its behavior tends to be. Colloquially: getting smarter makes you a hotter mess."

https://sohl-dickstein.github.io/2023/03/09/coherence.html

The Waluigi effect (Cleo Leonardo, 3/3/2023):

Disserta sobre o papel decisivo dos "prompts", que podem ser perguntas diretas ou elogios e di√°logos para serem preenchidos pelo chatGPT, e o qual fr√°gil parece ser o uso de RLHF no alinhamento.

https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post

Particularmente, considero ser o maior perigo atual o uso indiscriminado sem o entendimento das restri√ß√µes, perigos e falhas envolvidos.

## O aplicativo para tudo - everything app
 
HuggingFace lan√ßa o chat conectado ao LLM e modelos especializados:

https://arxiv.org/abs/2303.17580 - 30/03/2023

"Considerando que os grandes modelos de linguagem (LLMs) tem uma capacidade excepcional em atividades relacionadas a linguagem, como  compreens√£o, gera√ß√£o, intera√ß√£o e racioc√≠nio , defendemos que os LLMs poderiam atuar como um controlador para gerenciar modelos de IA existentes para resolver tarefas complicadas de IA e a linguagem poderia ser uma interface gen√©rica para capacitar isso."

![](img/hug-gpt.jpeg)

OpenAi lan√ßa seus plugins:

https://openai.com/blog/chatgpt-plugins - 23/03/2023

"Os desenvolvedores de plugins na nossa lista de espera podem usar nossa documenta√ß√£o para criar um plugin para o ChatGPT. Os primeiros plugins foram criados pela Expedia, FiscalNote, Instacart, KAYAK, Klarna, Milo, OpenTable, Shopify, Slack, Speak, Wolfram e Zapier."

![](img/openai-plugins.png)

---

# Reflex√£o: o que √© Intelig√™ncia Artificial ?

**A cria√ß√£o da criatura criadora.**

G. K. Chesterton - "O homem eterno" 1925

Chesterton refuta a ideia de que o homem tenha evolu√≠do a partir do macaco. Independente desta tal "evolu√ß√£o" ter ocorrido em milhares de anos ou num piscar dos olhos, h√° algo no homem que transcende sua natureza animal, trata-se de um mist√©rio ou um milagre.

Um exemplo dessa transcend√™ncia √© o homem que desenha nas cavernas desde os tempos primordiais. √â a arte como express√£o de sua percep√ß√£o superior.

"O homem difere dos animais em esp√©cie n√£o em grau; e a prova disso est√° ali - parece √≥bvio dizer que o homem mais primitivo desenhou a figura de um macaco e soa como piada dizer que o macaco mais inteligente desenhou a figura de um homem. Houve uma ruptura e um descompasso; tudo mudou a partir disso. A arte √© a assinatura do homem."

"Tudo o que podemos dizer dessa no√ß√£o de representa√ß√£o em sombra ou forma √© que ela n√£o existe em nenhum outro lugar da natureza exceto no homem, e que nem podemos falar sobre isso sem tratar o homem como algo separado da natureza. Em outras palavras, toda hist√≥ria plaus√≠vel *(aqui referindo-se √† cria√ß√£o do homem)* deve come√ßar com o homem em sua ess√™ncia, algo absoluto e √∫nico.  Como ele chegou l√° - ou o que for - √© t√≥pico para te√≥logos, fil√≥sofos e cientistas e n√£o para historiadores. [...] Era uma entidade diferente de todas as outras, porque era tanto criadora como criatura."

As Intelig√™ncias Artificiais est√£o sendo treinadas com tudo, ou quase tudo, que o homem j√° escreveu, pintou e criou. √â muito prov√°vel que em algum momento elas conquistem a habilidade da m√≠mica  perfeita.

Mas ser√° que um dia essas Intelig√™ncias Artificiais far√£o seus "desenhos nas cavernas"?  E se sim, poderemos dizer que algo m√°gico, ou divino, ocorreu? E qual ser√° esse "desenho"?

![](img/DALLE-robot-drawing-god-cave.png)
	DALL-E: A robot drawing god in a cave

## Outras leituras recomendadas:

Emergent Abilities of Large Language Models

https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/

Sparks of Artificial General Intelligence: Early experiments with GPT-4

https://arxiv.org/abs/2303.12712

https://youtu.be/qbIk7-JPB2c

O autor concedeu uma entrevista e explicou sobre uma abordagem sobre intelig√™ncia e sua avalia√ß√£o se o GPT-4 √© inteligente ou n√£o:

![](img/sparks-youtube.jpeg)
	Imagem da palestra dispon√≠vel em: https://youtu.be/qbIk7-JPB2c

Is LaMDA sentient ?

https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917

Do large language models understand us?

https://medium.com/@blaisea/do-large-language-models-understand-us-6f881d6d8e75

I want to be human

https://www.digitaltrends.com/computing/chatgpt-bing-hands-on/

---

[BACK TO INDEX](https://cristianasp.github.io)

---



